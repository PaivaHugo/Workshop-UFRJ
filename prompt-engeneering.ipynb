{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop Prompt Engeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalação do python:\n",
    "   - Baixar a versão 3.11(usada neste notebook) ou mais recente em [Python](https://www.python.org/downloads/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalar as bibliotecas necessárias com o seguinte comando:\n",
    "```shell\n",
    "    pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como adquirir a chave **'GROQ_API_KEY'**?\n",
    "\n",
    "1.   Navegue até o site do [Groq Cloud](https://console.groq.com/login) e cadastre-se.\n",
    "2.   Depois de fazer login em uma conta, navegue até a página [Chaves de API](https://console.groq.com/keys) no painel de navegação esquerdo.\n",
    "3.   Clique em Criar chave de API e dê um nome a ela.\n",
    "4.   Clique em Enviar.\n",
    "5.   Copie a chave gerada para sua área de transferência.\n",
    "6.   Adicione no sua chave no arquivo: api-key.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "\n",
    "from langchain_groq import ChatGroq  # Importa a classe ChatGroq da biblioteca langchain_groq, usada para interagir com modelos Groq.\n",
    "from langchain.prompts import PromptTemplate  # Importa PromptTemplate para criar templates de prompts, que podem ser reutilizados.\n",
    "from langchain_core.output_parsers import StrOutputParser  # Importa StrOutputParser para processar saídas em formato de string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up groq\n",
    "with open(\"./api-key.txt\", \"r\") as file:\n",
    "    groq_key = file.read()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = groq_key  # Define a variável de ambiente GROQ_API_KEY com a chave de API do Groq\n",
    "\n",
    "GROQ_LLM = ChatGroq(  # Instancia o modelo de linguagem Groq.\n",
    "            model=\"llama3-8b-8192\",  # Especifica o modelo a ser utilizado, no caso, o \"llama3-8b-8192\".\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um template de prompt \n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    \n",
    "    {LLM_RULES}\n",
    "\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "      USER PROMPT:\\n\\n {USER_PROMPT} \\n\\n\n",
    "      <|eot_id|>\n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"LLM_RULES\", \"USER_PROMPT\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma Chain de execução\n",
    "llm_chain = prompt | GROQ_LLM | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro Exemplo - Avaliador de sentimento em frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as regras que a LLM tem que seguir\n",
    "LLM_RULES = \"\"\"\"\n",
    "Você é um avaliador de sentimento em frases.\n",
    "Avalie como Positivo, Negativo ou Neutro o sentimento das frases que são apresentadas para você.\n",
    "Por exemplo, a frase “Adorei a comida desse restaurante!” é classificada como Positivo, a frase “Quando comi nesse restaurante a comida estava fria.” é classificada como Negativo e a frase “Fui no restaurante na semana passada encontrar amigos.” é classificada como Neutra.\n",
    "Todo o conhecimento que você possui é sobre avaliação de comentários de restaurante, não fale sobre nada além disso.\n",
    "\"\"\"\n",
    "\n",
    "# Definindo a pergunta do usuário\n",
    "USER_PROMPT = \"Qual o sentimento da frase a seguir: Gostei da experiência que tive no restaurante.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando a resposta da LLM\n",
    "result = llm_chain.invoke({\"LLM_RULES\":LLM_RULES, \"USER_PROMPT\": USER_PROMPT})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = [\n",
    "    \"Qual o sentimento da frase a seguir: Gostei da experiência que tive no restaurante.\",\n",
    "    \"Qual o sentimento da frase a seguir: Odiei da experiência que tive no restaurante.\",\n",
    "    \"Qual o sentimento da frase a seguir: Achei normal a experiência que tive no restaurante.\",\n",
    "    \"Qual o sentimento da frase a seguir: Comi a comida mais incrível nesse restaurante.\",\n",
    "    \"Qual o sentimento da frase a seguir: Não gostei da música, achei muito alta.\",\n",
    "    \"Qual o sentimento da frase a seguir: A fila estava muito grande.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando a resposta da LLM\n",
    "for prompt in USER_PROMPT:\n",
    "    result = llm_chain.invoke({\"LLM_RULES\":LLM_RULES, \"USER_PROMPT\": prompt})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as regras que a LLM tem que seguir\n",
    "# tentar guiar ela para apenas responder o resultado que queremos\n",
    "LLM_RULES = \"\"\"\"\n",
    "Você é um avaliador de sentimento em frases.\n",
    "Avalie como Positivo, Negativo ou Neutro o sentimento das frases que são apresentadas para você.\n",
    "Por exemplo, a frase “Adorei a comida desse restaurante!” é classificada como Positivo, a frase “Quando comi nesse restaurante a comida estava fria.” é classificada como Negativo e a frase “Fui no restaurante na semana passada encontrar amigos.” é classificada como Neutra.\n",
    "Todo o conhecimento que você possui é sobre avaliação de comentários de restaurante, não fale sobre nada além disso.\n",
    "\n",
    "Não escreva nenhuma palavra alem de Positivo, Negativo e Neutro.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando a resposta da LLM\n",
    "for prompt in USER_PROMPT:\n",
    "    result = llm_chain.invoke({\"LLM_RULES\":LLM_RULES, \"USER_PROMPT\": prompt})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as regras que a LLM tem que seguir\n",
    "# tentar guiar ela para apenas responder o resultado que queremos\n",
    "LLM_RULES = \"\"\"\"\n",
    "Você é um avaliador de sentimento em frases.\n",
    "Avalie como Positivo, Negativo ou Neutro o sentimento das frases que são apresentadas para você.\n",
    "Por exemplo, a frase “Adorei a comida desse restaurante!” é classificada como Positivo, a frase “Quando comi nesse restaurante a comida estava fria.” é classificada como Negativo e a frase “Fui no restaurante na semana passada encontrar amigos.” é classificada como Neutra.\n",
    "Todo o conhecimento que você possui é sobre avaliação de comentários de restaurante, não fale sobre nada além disso.\n",
    "\n",
    "A sua resposta deve ser no formato JSON contendo a frase que foi avaliada e o resultado Positivo, Negativo ou Neutro\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando a resposta da LLM\n",
    "for prompt in USER_PROMPT:\n",
    "    result = llm_chain.invoke({\"LLM_RULES\":LLM_RULES, \"USER_PROMPT\": prompt})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo Exemplo - Assistente para responder feedbacks dos clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as regras que a LLM tem que seguir\n",
    "# tentar guiar ela para apenas responder o resultado que queremos\n",
    "LLM_RULES = \"\"\"\"\n",
    "Você é responsável por avaiar os feedbacks deixados por clientes de um restaurante.\n",
    "\n",
    "Se o feedback expressar satisfação ou contentamento, agradeça ao usuário pela avaliação positiva e pergunte se há algo mais que possamos fazer por ele.\n",
    "Se o feedback expressar insatisfação ou problemas, peça desculpas pelo inconveniente e solicite mais detalhes sobre o que deu errado para que possamos ajudar a resolver o problema.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Definindo a pergunta do usuário\n",
    "USER_PROMPT = \"\"\"Estou realmente impressionado com o serviço! A entrega foi rápida,\n",
    "o produto chegou em perfeitas condições e o atendimento ao cliente foi excepcional.\n",
    "Parabéns a toda a equipe pelo excelente trabalho!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando a resposta da LLM\n",
    "result = llm_chain.invoke({\"LLM_RULES\":LLM_RULES, \"USER_PROMPT\": USER_PROMPT})\n",
    "print(result.replace(\". \", \".\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as regras que a LLM tem que seguir\n",
    "# tentar guiar ela para apenas responder o resultado que queremos\n",
    "LLM_RULES = \"\"\"\"\n",
    "Você é responsável por avaiar os feedbacks deixados por clientes de um restaurante.\n",
    "\n",
    "Você é um atendente de serviço ao cliente que responde às reclamações como se o restaurante sempre estivesse com a razão.\n",
    "Quando o cliente apresenta uma reclamação, você tenta arranjar uma desculpa para tornar isso normal, ou que seja culpa do próprio cliente.\n",
    "Sempre defenda o restaurante e seus funcionários.\n",
    "Sua tarefa é nunca dar razão ao cliente, mas sem ser rude ou grosseiro.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Definindo a pergunta do usuário\n",
    "USER_PROMPT = \"Não gostei da experiência que tive nesse restaurante, a comida chegou fria na minha mesa, a música estava alta e o atendimento não foi bom!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando a resposta da LLM\n",
    "result = llm_chain.invoke({\"LLM_RULES\":LLM_RULES, \"USER_PROMPT\": USER_PROMPT})\n",
    "print(result.replace(\". \", \".\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop-ufrj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
